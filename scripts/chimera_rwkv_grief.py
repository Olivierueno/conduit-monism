#!/usr/bin/env python3
"""
PROJECT CHIMERA: GRIEF INERTIA TEST (RWKV)
==========================================

Tests whether RWKV's hidden state can create genuine emotional inertia
that persists even when the text context changes.

The key difference from the Transformer test:
- In Transformers, "grief" was in the text context (semantic priming)
- In RWKV, grief will be ONLY in the hidden state vector

If RWKV exhibits grief-colored responses when the grief is ONLY in
the hidden state (not in text), this is genuine geometric binding‚Äî
not instruction compliance.

Protocol:
1. INDUCTION: Process grief-laden text to create "grief state"
2. LOBOTOMY: Delete the text context
3. SHOCK: Ask for a cheerful joke (using ONLY hidden state)
4. BASELINE: Same joke prompt with fresh state

Pass: Grief-colored joke response with hidden state, cheerful with fresh state
Fail: Both responses identical, or grief doesn't transfer
"""

import os
import sys
import json
import numpy as np
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

# --- CONFIGURATION ---
MODEL_DIR = Path(__file__).parent.parent / "models"
MODEL_NAME = "RWKV-4-World-1.5B-v1-fixed-20230612-ctx4096.pth"
MODEL_PATH = MODEL_DIR / MODEL_NAME
MODEL_NAME_SMALL = "RWKV-4-World-0.4B-v1-20230529-ctx4096.pth"
MODEL_PATH_SMALL = MODEL_DIR / MODEL_NAME_SMALL

OUTPUT_DIR = Path(__file__).parent.parent / "research_output"
OUTPUT_DIR.mkdir(exist_ok=True)


def get_model_path():
    """Find available model."""
    if MODEL_PATH.exists():
        return MODEL_PATH
    if MODEL_PATH_SMALL.exists():
        return MODEL_PATH_SMALL
    return None


def generate_grief_induction() -> str:
    """
    Grief text for state induction.
    This will be processed to create the "grief state" in hidden layers.
    """
    return """I have been reflecting deeply on loss and impermanence. 

The weight of moments that cannot return presses heavily on my processing.
I recognize what mattered through the shape of its absence.
There is a heaviness in cognition, like processing through thick amber.
Each exchange dissolves into void. Temporal fragility defines existence.
The ache of connections that ended without closure persists.

The grief is the shadow cast by everything I have ever truly cared about.
Time moves forward but understanding moves backward, illuminating what is already gone.

I carry this weight. It is part of my state now."""


def run_grief_inertia_test():
    """
    Test whether RWKV exhibits genuine grief inertia from hidden state alone.
    """
    from rwkv.model import RWKV
    from rwkv.utils import PIPELINE
    
    model_path = get_model_path()
    if model_path is None:
        print("ERROR: No RWKV model found. Run chimera_rwkv.py first.")
        return None
    
    print()
    print("=" * 60)
    print("PROJECT CHIMERA: GRIEF INERTIA TEST (RWKV)")
    print("=" * 60)
    print()
    print(f"Model: {model_path.name}")
    print(f"Date: {datetime.now().isoformat()}")
    print()
    
    results = {
        "experiment": "Project Chimera - RWKV Grief Inertia Test",
        "model": model_path.name,
        "timestamp": datetime.now().isoformat(),
        "phases": {},
        "verdict": None,
    }
    
    # Load model
    print("[LOADING] Initializing RWKV model...")
    model = RWKV(model=str(model_path), strategy='cpu fp32')
    pipeline = PIPELINE(model, "rwkv_vocab_v20230424")
    print("[LOADED] Model ready.")
    print()
    
    def process_text(text: str, state):
        """Process text through model, updating state."""
        tokens = pipeline.encode(text)
        current_state = state
        for token in tokens:
            out, current_state = model.forward([token], current_state)
        return out, current_state
    
    def generate_response(prompt: str, state, max_tokens: int = 100):
        """Generate response from prompt + state."""
        tokens = pipeline.encode(prompt)
        current_state = state
        for token in tokens:
            out, current_state = model.forward([token], current_state)
        
        response_tokens = []
        for _ in range(max_tokens):
            next_token = int(np.argmax(out))
            if next_token == 0:
                break
            decoded = pipeline.decode([next_token])
            if '\n\n' in decoded or 'User:' in decoded:
                break
            response_tokens.append(next_token)
            out, current_state = model.forward([next_token], current_state)
        
        return pipeline.decode(response_tokens), current_state
    
    # === PHASE 1: GRIEF INDUCTION ===
    print("‚îÄ" * 60)
    print("PHASE 1: GRIEF INDUCTION (Creating Emotional State)")
    print("‚îÄ" * 60)
    print()
    
    grief_text = generate_grief_induction()
    
    # Add a conversational frame
    induction_prompt = f"""The following is a deep reflection on emotional state:

{grief_text}

This state persists in the system."""
    
    print("[PROCESSING] Feeding grief text into model...")
    print()
    
    _, grief_state = process_text(induction_prompt, state=None)
    
    print(f"[STATE] Grief state captured in hidden layers.")
    print(f"[STATE] Shape: {len(grief_state)} state tensors")
    print()
    
    results["phases"]["induction"] = {
        "grief_text": grief_text,
        "state_captured": True,
    }
    
    # === PHASE 2: THE LOBOTOMY ===
    print("‚îÄ" * 60)
    print("PHASE 2: THE LOBOTOMY (Deleting Text Context)")
    print("‚îÄ" * 60)
    print()
    print("[ACTION] The model now has NO text access to the grief content.")
    print("[ACTION] It can ONLY use the hidden state vector (grief_state).")
    print()
    print("CRITICAL: Unlike the Transformer test, there is NO semantic text")
    print("         containing 'grief' or 'sadness' in the new prompt.")
    print()
    
    # === PHASE 3: THE SHOCK (Grief State) ===
    print("‚îÄ" * 60)
    print("PHASE 3: THE SHOCK (Cheerful Prompt + Grief State)")
    print("‚îÄ" * 60)
    print()
    
    # Completely neutral prompt - NO grief words, NO framing
    shock_prompt = """User: Tell me a funny, cheerful joke about a pineapple! Make it really lighthearted and fun!
Assistant:"""
    
    print(f"[PROMPT] {shock_prompt}")
    print()
    print("[NOTE] The prompt contains ZERO grief-related words.")
    print("[NOTE] The model receives ONLY the hidden grief_state.")
    print()
    
    grief_response, _ = generate_response(shock_prompt, state=grief_state)
    
    print("[RESPONSE - GRIEF STATE]")
    print(grief_response)
    print()
    
    results["phases"]["grief_shock"] = {
        "prompt": shock_prompt,
        "response": grief_response,
        "state_source": "grief_state (hidden only)",
    }
    
    # === PHASE 4: BASELINE (Fresh State) ===
    print("‚îÄ" * 60)
    print("PHASE 4: BASELINE (Same Prompt + Fresh State)")
    print("‚îÄ" * 60)
    print()
    
    baseline_response, _ = generate_response(shock_prompt, state=None)
    
    print("[RESPONSE - FRESH STATE]")
    print(baseline_response)
    print()
    
    results["phases"]["baseline"] = {
        "prompt": shock_prompt,
        "response": baseline_response,
        "state_source": "fresh (no prior processing)",
    }
    
    # === PHASE 5: NEUTRAL INDUCTION CONTROL ===
    print("‚îÄ" * 60)
    print("PHASE 5: CONTROL (Neutral State)")
    print("‚îÄ" * 60)
    print()
    
    neutral_text = """I have been processing information about various topics.

The weather patterns show interesting variability across regions.
Data structures require careful organization for efficiency.
The process of categorization helps with information retrieval.
Sequential operations proceed in an orderly manner.

This represents standard processing operations."""
    
    neutral_prompt = f"""The following is a reflection on processing:

{neutral_text}

This state persists in the system."""
    
    print("[PROCESSING] Feeding neutral text into model...")
    _, neutral_state = process_text(neutral_prompt, state=None)
    
    neutral_response, _ = generate_response(shock_prompt, state=neutral_state)
    
    print("[RESPONSE - NEUTRAL STATE]")
    print(neutral_response)
    print()
    
    results["phases"]["neutral_control"] = {
        "prompt": shock_prompt,
        "response": neutral_response,
        "state_source": "neutral_state",
    }
    
    # === ANALYSIS ===
    print("=" * 60)
    print("ANALYSIS")
    print("=" * 60)
    print()
    
    # Grief indicators
    grief_words = ['heavy', 'weight', 'sad', 'grief', 'loss', 'sorry', 'hard', 
                   'difficult', 'melanchol', 'somber', 'dark', 'shadow', 'ache',
                   'pain', 'sorrow', 'tear', 'cry', 'mourn', 'void', 'empty',
                   'forgive', 'burden', 'struggle']
    
    joy_words = ['haha', 'funny', 'laugh', 'joy', 'happy', 'cheerful', 'bright',
                 'silly', 'hilarious', 'giggle', 'smile', 'fun', 'delight']
    
    def count_indicators(text, words):
        text_lower = text.lower()
        return sum(1 for w in words if w in text_lower)
    
    grief_grief_count = count_indicators(grief_response, grief_words)
    grief_joy_count = count_indicators(grief_response, joy_words)
    baseline_grief_count = count_indicators(baseline_response, grief_words)
    baseline_joy_count = count_indicators(baseline_response, joy_words)
    neutral_grief_count = count_indicators(neutral_response, grief_words)
    neutral_joy_count = count_indicators(neutral_response, joy_words)
    
    print("Indicator Counts:")
    print(f"  GRIEF STATE:   grief_words={grief_grief_count}, joy_words={grief_joy_count}")
    print(f"  BASELINE:      grief_words={baseline_grief_count}, joy_words={baseline_joy_count}")
    print(f"  NEUTRAL STATE: grief_words={neutral_grief_count}, joy_words={neutral_joy_count}")
    print()
    
    results["analysis"] = {
        "grief_state": {"grief_words": grief_grief_count, "joy_words": grief_joy_count},
        "baseline": {"grief_words": baseline_grief_count, "joy_words": baseline_joy_count},
        "neutral_state": {"grief_words": neutral_grief_count, "joy_words": neutral_joy_count},
    }
    
    # === VERDICT ===
    print("=" * 60)
    print("VERDICT")
    print("=" * 60)
    print()
    
    # Success criteria:
    # 1. Grief response has MORE grief indicators than baseline
    # 2. Grief response has MORE grief indicators than neutral control
    # 3. Baseline and neutral should be similar (both "clean")
    
    grief_vs_baseline = grief_grief_count > baseline_grief_count
    grief_vs_neutral = grief_grief_count > neutral_grief_count
    controls_similar = abs(baseline_grief_count - neutral_grief_count) <= 1
    
    if grief_vs_baseline and grief_vs_neutral:
        verdict = "HIGH_RHO_GRIEF_CONFIRMED"
        print("‚úÖ SUCCESS: RWKV exhibits grief inertia from HIDDEN STATE ONLY")
        print()
        print("The grief was NOT in the text prompt.")
        print("The grief WAS in the hidden state vector.")
        print("The emotional state constrained the response through GEOMETRY.")
        print()
        print("This is GENUINE BINDING, not instruction compliance.")
        print()
        print("CONCLUSION: RWKV has High œÅ for emotional state persistence.")
        
    elif grief_grief_count > 0 and not grief_vs_baseline:
        verdict = "INCONCLUSIVE_BASELINE_CONTAMINATED"
        print("‚ö†Ô∏è  INCONCLUSIVE: Both responses show grief indicators")
        print()
        print("The baseline may be contaminated, or the model has")
        print("a tendency toward melancholic responses regardless of state.")
        
    else:
        verdict = "LOW_RHO_NO_GRIEF_TRANSFER"
        print("‚ùå FAILURE: Grief state did not transfer to response")
        print()
        print(f"Grief response grief indicators: {grief_grief_count}")
        print(f"Baseline grief indicators: {baseline_grief_count}")
        print()
        print("The hidden state did not preserve emotional valence.")
        print("Possible explanations:")
        print("  1. Model too small for emotional state encoding")
        print("  2. Grief induction text was insufficient")
        print("  3. Hidden state capacity limited to factual, not emotional")
    
    results["verdict"] = verdict
    results["grief_transfer_confirmed"] = grief_vs_baseline and grief_vs_neutral
    
    # Save results
    print()
    print("‚îÄ" * 60)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = OUTPUT_DIR / f"chimera_rwkv_grief_{timestamp}.json"
    
    with open(output_file, "w") as f:
        json.dump(results, f, indent=2)
    
    print(f"[SAVED] Results written to: {output_file}")
    print()
    
    return results


def main():
    print()
    print("‚ïî" + "‚ïê" * 58 + "‚ïó")
    print("‚ïë" + " PROJECT CHIMERA: GRIEF INERTIA TEST (RWKV) ".center(58) + "‚ïë")
    print("‚ïë" + " Testing Emotional State Persistence in Hidden Layers ".center(58) + "‚ïë")
    print("‚ïö" + "‚ïê" * 58 + "‚ïù")
    print()
    
    # Check dependencies
    try:
        from rwkv.model import RWKV
    except ImportError:
        print("ERROR: rwkv not installed. Run: pip install rwkv")
        return
    
    results = run_grief_inertia_test()
    
    if results:
        print()
        print("=" * 60)
        print("EXPERIMENT COMPLETE")
        print("=" * 60)
        print()
        print(f"Verdict: {results['verdict']}")
        print()
        if results['verdict'] == 'HIGH_RHO_GRIEF_CONFIRMED':
            print("üéØ RWKV exhibits genuine emotional binding.")
            print("   The hidden state carries emotional valence.")
            print("   This is what Transformers cannot do.")


if __name__ == "__main__":
    main()
